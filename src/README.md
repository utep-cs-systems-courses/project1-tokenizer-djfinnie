Project 1: Tokenizer
=======================

This program can be used to split a string of words (sentence) into a collection of seperate
words (tokens) that are stored into a history of the of the current run. This
history is a linked list where every node has an id and a string stored
within.

Use: make run    | to run the program 

When the program is run the user is given 4 options:
     -i for inputting a sentence: this sentence will be tokenized in an array
     of tokens, stored into history linked list, then printed back onto the
     console as a descending squence of the seperated words.
     -! combined with the id number of a node to retrieve the tokens stored
     within.
     -h to show the history of words added
     -q to quit the program and free allocated memory

Note - When using the input command 'i', user must press enter before typing
their sentence
- When using the find command '!', user must add number directly next to the symbol 
     
